{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XPENzXGU1XzL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/content/expanded_dataset_with_names.xlsx')\n",
        "df = pd.DataFrame(data)\n",
        "items = df.iloc[:, 1:]\n",
        "items"
      ],
      "metadata": {
        "id": "wmA0NFy56b06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "13c47cbc-dbcb-4262-a5c5-49329c327045"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    jane eyre  1984  wuthering  picture of dorian   catcher in rye  \\\n",
              "0         NaN   5.0          1                 4.0             4.0   \n",
              "1         0.0   5.0          0                 5.0             2.0   \n",
              "2         NaN   5.0          3                 NaN             4.0   \n",
              "3         5.0   1.0          1                 4.0             1.0   \n",
              "4         5.0   NaN          4                 0.0             4.0   \n",
              "5         1.0   1.0          3                 5.0             4.0   \n",
              "6         3.0   NaN          3                 NaN             NaN   \n",
              "7         3.0   4.0          1                 5.0             1.0   \n",
              "8         5.0   1.0          4                 5.0             5.0   \n",
              "9         3.0   4.0          3                 5.0             4.0   \n",
              "10        3.0   NaN          3                 0.0             4.0   \n",
              "11        3.0   4.0          3                 1.0             5.0   \n",
              "12        3.0   4.0          3                 5.0             5.0   \n",
              "13        3.0   0.0          0                 NaN             4.0   \n",
              "14        NaN   4.0          4                 NaN             5.0   \n",
              "15        0.0   4.0          1                 NaN             NaN   \n",
              "16        5.0   NaN          2                 NaN             3.0   \n",
              "17        NaN   0.0          0                 NaN             3.0   \n",
              "18        1.0   3.0          4                 NaN             3.0   \n",
              "19        1.0   NaN          1                 NaN             0.0   \n",
              "20        0.0   4.0          3                 NaN             1.0   \n",
              "21        5.0   4.0          0                 NaN             4.0   \n",
              "22        5.0   5.0          3                 NaN             4.0   \n",
              "23        2.0   5.0          4                 NaN             NaN   \n",
              "24        5.0   2.0          5                 NaN             4.0   \n",
              "25        4.0   NaN          0                 NaN             3.0   \n",
              "26        1.0   2.0          5                 NaN             1.0   \n",
              "27        0.0   5.0          1                 NaN             0.0   \n",
              "28        3.0   3.0          3                 NaN             0.0   \n",
              "29        0.0   2.0          2                 NaN             2.0   \n",
              "30        5.0   4.0          0                 NaN             3.0   \n",
              "31        NaN   NaN          5                 NaN             0.0   \n",
              "32        NaN   5.0          1                 NaN             1.0   \n",
              "33        NaN   2.0          1                 NaN             3.0   \n",
              "34        0.0   4.0          4                 NaN             0.0   \n",
              "35        2.0   2.0          1                 NaN             NaN   \n",
              "36        5.0   NaN          5                 NaN             0.0   \n",
              "37        NaN   3.0          1                 NaN             NaN   \n",
              "38        1.0   NaN          1                 NaN             NaN   \n",
              "39        4.0   3.0          3                 NaN             NaN   \n",
              "40        5.0   3.0          4                 NaN             0.0   \n",
              "41        1.0   4.0          0                 NaN             0.0   \n",
              "42        4.0   1.0          4                 NaN             2.0   \n",
              "\n",
              "    sense and sensibility  great expectations  tale of cities  \\\n",
              "0                     0.0                 4.0             4.0   \n",
              "1                     4.0                 0.0             3.0   \n",
              "2                     4.0                 5.0             NaN   \n",
              "3                     3.0                 3.0             3.0   \n",
              "4                     4.0                 0.0             3.0   \n",
              "5                     4.0                 5.0             4.0   \n",
              "6                     5.0                 NaN             3.0   \n",
              "7                     2.0                 4.0             5.0   \n",
              "8                     5.0                 2.0             NaN   \n",
              "9                     NaN                 3.0             3.0   \n",
              "10                    4.0                 5.0             3.0   \n",
              "11                    NaN                 NaN             5.0   \n",
              "12                    4.0                 5.0             0.0   \n",
              "13                    3.0                 1.0             2.0   \n",
              "14                    5.0                 5.0             0.0   \n",
              "15                    5.0                 NaN             3.0   \n",
              "16                    5.0                 2.0             3.0   \n",
              "17                    5.0                 1.0             1.0   \n",
              "18                    4.0                 4.0             NaN   \n",
              "19                    2.0                 NaN             1.0   \n",
              "20                    4.0                 2.0             NaN   \n",
              "21                    NaN                 1.0             0.0   \n",
              "22                    2.0                 1.0             3.0   \n",
              "23                    4.0                 1.0             2.0   \n",
              "24                    3.0                 4.0             1.0   \n",
              "25                    1.0                 NaN             2.0   \n",
              "26                    5.0                 1.0             1.0   \n",
              "27                    5.0                 0.0             3.0   \n",
              "28                    2.0                 NaN             2.0   \n",
              "29                    1.0                 1.0             1.0   \n",
              "30                    4.0                 4.0             3.0   \n",
              "31                    NaN                 1.0             2.0   \n",
              "32                    5.0                 5.0             NaN   \n",
              "33                    NaN                 4.0             5.0   \n",
              "34                    3.0                 3.0             0.0   \n",
              "35                    3.0                 2.0             5.0   \n",
              "36                    1.0                 1.0             5.0   \n",
              "37                    1.0                 1.0             3.0   \n",
              "38                    2.0                 1.0             3.0   \n",
              "39                    2.0                 2.0             2.0   \n",
              "40                    1.0                 2.0             5.0   \n",
              "41                    NaN                 3.0             1.0   \n",
              "42                    5.0                 0.0             5.0   \n",
              "\n",
              "    brave new world  macbeth  The Great Gatsby  picture of dorian  \n",
              "0               0.0      5.0              3.93                NaN  \n",
              "1               5.0      NaN               NaN                NaN  \n",
              "2               3.0      2.0              3.00                NaN  \n",
              "3               3.0      2.0              0.00                NaN  \n",
              "4               4.0      5.0              2.00                NaN  \n",
              "5               3.0      5.0               NaN                NaN  \n",
              "6               4.0      NaN              5.00                NaN  \n",
              "7               2.0      4.0              5.00                NaN  \n",
              "8               3.0      5.0              5.00                NaN  \n",
              "9               4.0      5.0               NaN                NaN  \n",
              "10              0.0      NaN              3.00                NaN  \n",
              "11              5.0      5.0              2.00                NaN  \n",
              "12              5.0      2.0              2.00                NaN  \n",
              "13              4.0      0.0              4.00                4.0  \n",
              "14              5.0      1.0              3.00                2.0  \n",
              "15              1.0      0.0              1.00                2.0  \n",
              "16              5.0      NaN              2.00                4.0  \n",
              "17              0.0      2.0              5.00                4.0  \n",
              "18              4.0      1.0               NaN                5.0  \n",
              "19              2.0      NaN              3.00                4.0  \n",
              "20              3.0      3.0              3.00                4.0  \n",
              "21              0.0      4.0              1.00                0.0  \n",
              "22              4.0      1.0              4.00                3.0  \n",
              "23              5.0      4.0              2.00                NaN  \n",
              "24              2.0      1.0              2.00                NaN  \n",
              "25              4.0      5.0               NaN                0.0  \n",
              "26              5.0      4.0               NaN                2.0  \n",
              "27              4.0      2.0              1.00                4.0  \n",
              "28              4.0      NaN              0.00                4.0  \n",
              "29              5.0      2.0               NaN                0.0  \n",
              "30              1.0      3.0              0.00                4.0  \n",
              "31              0.0      3.0              3.00                4.0  \n",
              "32              2.0      3.0              5.00                3.0  \n",
              "33              3.0      NaN              2.00                4.0  \n",
              "34              4.0      4.0              5.00                2.0  \n",
              "35              2.0      NaN              2.00                0.0  \n",
              "36              0.0      5.0              0.00                1.0  \n",
              "37              2.0      1.0              3.00                NaN  \n",
              "38              5.0      0.0              2.00                3.0  \n",
              "39              0.0      3.0              2.00                1.0  \n",
              "40              4.0      0.0              5.00                4.0  \n",
              "41              NaN      NaN               NaN                0.0  \n",
              "42              4.0      NaN              2.00                5.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e5a593f-384d-4572-99d4-d67d8325ea62\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jane eyre</th>\n",
              "      <th>1984</th>\n",
              "      <th>wuthering</th>\n",
              "      <th>picture of dorian</th>\n",
              "      <th>catcher in rye</th>\n",
              "      <th>sense and sensibility</th>\n",
              "      <th>great expectations</th>\n",
              "      <th>tale of cities</th>\n",
              "      <th>brave new world</th>\n",
              "      <th>macbeth</th>\n",
              "      <th>The Great Gatsby</th>\n",
              "      <th>picture of dorian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.93</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.00</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.00</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.00</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e5a593f-384d-4572-99d4-d67d8325ea62')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e5a593f-384d-4572-99d4-d67d8325ea62 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e5a593f-384d-4572-99d4-d67d8325ea62');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-54f4ca71-1e63-4bcc-a80f-fd7fc7acce6b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-54f4ca71-1e63-4bcc-a80f-fd7fc7acce6b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-54f4ca71-1e63-4bcc-a80f-fd7fc7acce6b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f5bf0a3a-5d6e-4f45-ada9-b27b81d405c5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('items')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f5bf0a3a-5d6e-4f45-ada9-b27b81d405c5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('items');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "items",
              "summary": "{\n  \"name\": \"items\",\n  \"rows\": 43,\n  \"fields\": [\n    {\n      \"column\": \"jane eyre\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8840328638144224,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.0,\n          5.0,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1984\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5269416498802555,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5.0,\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wuthering\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1,\n          0,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"picture of dorian \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1148823307047775,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          5.0,\n          1.0,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"catcher in rye\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7806276760274506,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0,\n          2.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sense and sensibility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.506741607001768,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.0,\n          4.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"great expectations\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6908160334166635,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0,\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tale of cities\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5669052409572835,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0,\n          3.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"brave new world\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7459094385769165,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.0,\n          5.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macbeth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7456656280194343,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5.0,\n          2.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"The Great Gatsby\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5876589710650588,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          3.93,\n          3.0,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"picture of dorian\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6828276298863267,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4.0,\n          2.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tnu = len(df['users'])\n",
        "tni = len(items.columns)"
      ],
      "metadata": {
        "id": "3PujOaJA6lYX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tnu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWB1rZFXxMGj",
        "outputId": "3c4c818e-2c34-4094-98be-203a1cc8178a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tni"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjezE_ZaxOvL",
        "outputId": "cd957d0f-68d9-4758-bdc8-f3c515732079"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_null_counts = df.count()\n",
        "\n",
        "print(\"Non-null values in each column:\")\n",
        "print(non_null_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4qQ5Ke97V_L",
        "outputId": "0fb7dd1b-48c0-408d-e98b-56298ff02b46"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-null values in each column:\n",
            "users                    43\n",
            "jane eyre                35\n",
            "1984                     34\n",
            "wuthering                43\n",
            "picture of dorian        11\n",
            "catcher in rye           36\n",
            "sense and sensibility    37\n",
            "great expectations       37\n",
            "tale of cities           38\n",
            "brave new world          42\n",
            "macbeth                  33\n",
            "The Great Gatsby         35\n",
            "picture of dorian        27\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "U1 = df[df.isnull().sum(axis=1) == 2]\n",
        "U1 = U1.iloc[1,:]\n",
        "U2 = df[df.isnull().sum(axis=1) == 3]\n",
        "U3 = df[df.isnull().sum(axis=1) ==5 ]\n",
        "\n",
        "U3"
      ],
      "metadata": {
        "id": "BxGFXjOK7W-H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "7e8b0ad0-4e76-4065-ecb1-681e2a37640a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               users  jane eyre  1984  wuthering  picture of dorian   \\\n",
              "41  Christine Lawson        1.0   4.0          0                 NaN   \n",
              "\n",
              "    catcher in rye  sense and sensibility  great expectations  tale of cities  \\\n",
              "41             0.0                    NaN                 3.0             1.0   \n",
              "\n",
              "    brave new world  macbeth  The Great Gatsby  picture of dorian  \n",
              "41              NaN      NaN               NaN                0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40f38bc1-eadf-47bf-8a12-91264b40b0c5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>users</th>\n",
              "      <th>jane eyre</th>\n",
              "      <th>1984</th>\n",
              "      <th>wuthering</th>\n",
              "      <th>picture of dorian</th>\n",
              "      <th>catcher in rye</th>\n",
              "      <th>sense and sensibility</th>\n",
              "      <th>great expectations</th>\n",
              "      <th>tale of cities</th>\n",
              "      <th>brave new world</th>\n",
              "      <th>macbeth</th>\n",
              "      <th>The Great Gatsby</th>\n",
              "      <th>picture of dorian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Christine Lawson</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40f38bc1-eadf-47bf-8a12-91264b40b0c5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-40f38bc1-eadf-47bf-8a12-91264b40b0c5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-40f38bc1-eadf-47bf-8a12-91264b40b0c5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_1f692810-0ce2-4362-b491-8291675baf51\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('U3')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1f692810-0ce2-4362-b491-8291675baf51 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('U3');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "U3",
              "summary": "{\n  \"name\": \"U3\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"users\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Christine Lawson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jane eyre\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1984\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 4.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wuthering\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"picture of dorian \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"catcher in rye\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sense and sensibility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"great expectations\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 3.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tale of cities\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"brave new world\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macbeth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"The Great Gatsby\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"picture of dorian\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_ratings_per_item = items.isna().sum(axis=0)\n",
        "target_percentages = [0.04, 0.2]\n",
        "total_users = items.shape[0]\n",
        "target_missing_counts = [int(total_users * target) for target in target_percentages]\n",
        "closest_items = []\n",
        "for target_count in target_missing_counts:\n",
        "    closest_item = missing_ratings_per_item.abs() - target_count\n",
        "    closest_item = closest_item.idxmin()\n",
        "    closest_items.append(closest_item)\n",
        "\n",
        "I1_index, I2_index = closest_items\n",
        "print(f\"Selected target items: I1 = {I1_index}, I2 = {I2_index}\")\n"
      ],
      "metadata": {
        "id": "4pRuFDng-Z33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a9db3e-01eb-435d-e86b-483c7cfe1dfe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected target items: I1 = wuthering, I2 = wuthering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "U2.dropna(axis=1, inplace=True)\n",
        "U2_columns = U2.columns\n",
        "co_rated_users = df[U2_columns].notna().any(axis=1)\n",
        "co_rated_user_indices = co_rated_users[co_rated_users].index\n",
        "No_common_users = len(co_rated_user_indices)\n",
        "No_coRated_items = df.loc[co_rated_user_indices, U2_columns].notna().sum().sum()\n",
        "print(f\"Number of users with co-rated items: {No_common_users}\")\n",
        "print(f\"Number of co-rated items: {No_coRated_items}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAW7T1t_4nkl",
        "outputId": "9e7122d6-bfb8-4dad-efab-e1248921cdad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users with co-rated items: 43\n",
            "Number of co-rated items: 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-3f057065964e>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  U2.dropna(axis=1, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "U3.dropna(axis=1, inplace=True)\n",
        "U3_columns = U3.columns\n",
        "\n",
        "co_rated_users = df[U3_columns].notna().any(axis=1)\n",
        "co_rated_user_indices = co_rated_users[co_rated_users].index\n",
        "No_common_users = len(co_rated_user_indices)\n",
        "No_coRated_items = df.loc[co_rated_user_indices, U3_columns].notna().sum().sum()\n",
        "\n",
        "print(f\"Number of users with co-rated items: {No_common_users}\")\n",
        "print(f\"Number of co-rated items: {No_coRated_items}\")\n",
        "result = [(No_common_users, No_coRated_items)]\n",
        "result = sorted(result, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "print(\"2D Array (No_common_users, No_coRated_items):\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4gHC_eyWMMQ",
        "outputId": "61189b03-32f3-473e-d29c-d71d4947c334"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users with co-rated items: 43\n",
            "Number of co-rated items: 293\n",
            "2D Array (No_common_users, No_coRated_items):\n",
            "[(43, 293)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-d58b342ae2b6>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  U3.dropna(axis=1, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "active_user_idx = 2\n",
        "U2 = df.loc[[active_user_idx]].copy()\n",
        "U2.dropna(axis=1, inplace=True)\n",
        "U2_columns = U2.columns\n",
        "co_rated_users = df[U2_columns].notna().any(axis=1)\n",
        "co_rated_user_indices = co_rated_users[co_rated_users].index\n",
        "co_rated_user_indices = co_rated_user_indices.difference([active_user_idx])\n",
        "no_common_users_list = []\n",
        "no_coRated_items_list = []\n",
        "for user_idx in co_rated_user_indices:\n",
        "\n",
        "    co_rated_items = df.loc[[active_user_idx, user_idx], U2_columns].notna().all(axis=0)\n",
        "    no_coRated_items = co_rated_items.sum()\n",
        "\n",
        "    if no_coRated_items > 0:\n",
        "        no_common_users_list.append(1)\n",
        "        no_coRated_items_list.append(no_coRated_items)\n",
        "\n",
        "\n",
        "no_common_users = sum(no_common_users_list)\n",
        "result_array = np.column_stack((no_common_users_list, no_coRated_items_list))\n",
        "\n",
        "sorted_result_array = result_array[np.argsort(-result_array[:, 0])]\n",
        "\n",
        "print(f\"Number of users with co-rated items: {no_common_users}\")\n",
        "print(f\"Resulting 2D array (sorted):\\n{sorted_result_array}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PWkb_-GzVbn",
        "outputId": "68d75615-740e-4e8f-f120-45328cdd283d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users with co-rated items: 42\n",
            "Resulting 2D array (sorted):\n",
            "[[1 9]\n",
            " [1 9]\n",
            " [1 6]\n",
            " [1 8]\n",
            " [1 9]\n",
            " [1 7]\n",
            " [1 8]\n",
            " [1 9]\n",
            " [1 7]\n",
            " [1 9]\n",
            " [1 7]\n",
            " [1 9]\n",
            " [1 7]\n",
            " [1 8]\n",
            " [1 8]\n",
            " [1 7]\n",
            " [1 8]\n",
            " [1 9]\n",
            " [1 8]\n",
            " [1 9]\n",
            " [1 8]\n",
            " [1 9]\n",
            " [1 7]\n",
            " [1 9]\n",
            " [1 8]\n",
            " [1 8]\n",
            " [1 5]\n",
            " [1 9]\n",
            " [1 9]\n",
            " [1 7]\n",
            " [1 5]\n",
            " [1 7]\n",
            " [1 9]\n",
            " [1 9]\n",
            " [1 9]\n",
            " [1 7]\n",
            " [1 7]\n",
            " [1 9]\n",
            " [1 8]\n",
            " [1 6]\n",
            " [1 7]\n",
            " [1 8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "active_user_idx = 0\n",
        "U2 = df.loc[[active_user_idx]].copy()\n",
        "U2.dropna(axis=1, inplace=True)\n",
        "U2_columns = U2.columns\n",
        "co_rated_users = df[U2_columns].notna().any(axis=1)\n",
        "co_rated_user_indices = co_rated_users[co_rated_users].index\n",
        "co_rated_user_indices = co_rated_user_indices.difference([active_user_idx])\n",
        "no_common_users_list = []\n",
        "no_coRated_items_list = []\n",
        "for user_idx in co_rated_user_indices:\n",
        "\n",
        "    co_rated_items = df.loc[[active_user_idx, user_idx], U2_columns].notna().all(axis=0)\n",
        "    no_coRated_items = co_rated_items.sum()\n",
        "\n",
        "    if no_coRated_items > 0:\n",
        "        no_common_users_list.append(1)\n",
        "        no_coRated_items_list.append(no_coRated_items)\n",
        "\n",
        "\n",
        "no_common_users = sum(no_common_users_list)\n",
        "result_array = np.column_stack((no_common_users_list, no_coRated_items_list))\n",
        "\n",
        "sorted_result_array = result_array[np.argsort(-result_array[:, 0])]\n",
        "\n",
        "print(f\"Number of users with co-rated items: {no_common_users}\")\n",
        "print(f\"Resulting 2D array (sorted):\\n{sorted_result_array}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DKJ5-SewAjd",
        "outputId": "54da106d-c123-410b-e210-c1de3d2e03da"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users with co-rated items: 42\n",
            "Resulting 2D array (sorted):\n",
            "[[ 1  9]\n",
            " [ 1 10]\n",
            " [ 1  7]\n",
            " [ 1  9]\n",
            " [ 1 10]\n",
            " [ 1  8]\n",
            " [ 1  9]\n",
            " [ 1 10]\n",
            " [ 1  8]\n",
            " [ 1  9]\n",
            " [ 1  8]\n",
            " [ 1 10]\n",
            " [ 1  8]\n",
            " [ 1  9]\n",
            " [ 1  9]\n",
            " [ 1  8]\n",
            " [ 1  9]\n",
            " [ 1 10]\n",
            " [ 1  9]\n",
            " [ 1 10]\n",
            " [ 1  9]\n",
            " [ 1  9]\n",
            " [ 1  9]\n",
            " [ 1 11]\n",
            " [ 1 10]\n",
            " [ 1 10]\n",
            " [ 1  6]\n",
            " [ 1 11]\n",
            " [ 1 10]\n",
            " [ 1  9]\n",
            " [ 1  6]\n",
            " [ 1  9]\n",
            " [ 1 11]\n",
            " [ 1 10]\n",
            " [ 1 10]\n",
            " [ 1  8]\n",
            " [ 1  8]\n",
            " [ 1 10]\n",
            " [ 1  8]\n",
            " [ 1  7]\n",
            " [ 1  9]\n",
            " [ 1  9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "active_user_idx = 5\n",
        "U3 = df.loc[[active_user_idx]].copy()\n",
        "U3.dropna(axis=1, inplace=True)\n",
        "\n",
        "U3_columns = U3.columns\n",
        "\n",
        "\n",
        "co_rated_users = df[U3_columns].notna().any(axis=1)\n",
        "co_rated_user_indices = co_rated_users[co_rated_users].index\n",
        "co_rated_user_indices = co_rated_user_indices.difference([active_user_idx])\n",
        "\n",
        "\n",
        "no_common_users_list = []\n",
        "no_coRated_items_list = []\n",
        "\n",
        "for user_idx in co_rated_user_indices:\n",
        "\n",
        "    co_rated_items = df.loc[[active_user_idx, user_idx], U2_columns].notna().all(axis=0)\n",
        "    no_coRated_items = co_rated_items.sum()\n",
        "\n",
        "    if no_coRated_items > 0:\n",
        "        no_common_users_list.append(1)\n",
        "        no_coRated_items_list.append(no_coRated_items)\n",
        "\n",
        "\n",
        "no_common_users = sum(no_common_users_list)\n",
        "result_array = np.column_stack((no_common_users_list, no_coRated_items_list))\n",
        "\n",
        "sorted_result_array = result_array[np.argsort(-result_array[:, 0])]\n",
        "\n",
        "print(f\"Number of users with co-rated items: {no_common_users}\")\n",
        "print(f\"Resulting 2D array (sorted):\\n{sorted_result_array}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ89yVE3ynDM",
        "outputId": "a18d3a51-8553-4bf4-81c4-d971442199fc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users with co-rated items: 42\n",
            "Resulting 2D array (sorted):\n",
            "[[ 1 10]\n",
            " [ 1  9]\n",
            " [ 1  7]\n",
            " [ 1  9]\n",
            " [ 1  9]\n",
            " [ 1  7]\n",
            " [ 1  9]\n",
            " [ 1  9]\n",
            " [ 1  7]\n",
            " [ 1  8]\n",
            " [ 1  7]\n",
            " [ 1  9]\n",
            " [ 1  7]\n",
            " [ 1  8]\n",
            " [ 1  8]\n",
            " [ 1  7]\n",
            " [ 1  8]\n",
            " [ 1  9]\n",
            " [ 1  8]\n",
            " [ 1  9]\n",
            " [ 1  8]\n",
            " [ 1  8]\n",
            " [ 1  9]\n",
            " [ 1  8]\n",
            " [ 1 10]\n",
            " [ 1  9]\n",
            " [ 1  5]\n",
            " [ 1 10]\n",
            " [ 1  9]\n",
            " [ 1  9]\n",
            " [ 1  6]\n",
            " [ 1  8]\n",
            " [ 1 10]\n",
            " [ 1  9]\n",
            " [ 1  9]\n",
            " [ 1  7]\n",
            " [ 1  7]\n",
            " [ 1  9]\n",
            " [ 1  8]\n",
            " [ 1  6]\n",
            " [ 1  8]\n",
            " [ 1  8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 1: Find co-rated items between all pairs of users\n",
        "num_users = len(df)\n",
        "results = []\n",
        "\n",
        "for i in range(num_users):\n",
        "    for j in range(i + 1, num_users):  # Compare each unique pair of users\n",
        "        # Find items co-rated by both users\n",
        "        co_rated_items = df.loc[i].notna() & df.loc[j].notna()\n",
        "        no_coRated_items = co_rated_items.sum()  # Count of co-rated items\n",
        "\n",
        "        if no_coRated_items > 0:\n",
        "            results.append((2, no_coRated_items))  # Append as a tuple: (2 users, co-rated items)\n",
        "\n",
        "# Step 2: Print the final result as a list of tuples\n",
        "print(\"Final List of Tuples:\")\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMux4RqS1hgX",
        "outputId": "1247125f-7461-4e1f-e1bf-8b6c179fc6f2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final List of Tuples:\n",
            "[(2, 9), (2, 9), (2, 11), (2, 10), (2, 10), (2, 6), (2, 11), (2, 10), (2, 9), (2, 9), (2, 9), (2, 11), (2, 10), (2, 10), (2, 8), (2, 8), (2, 10), (2, 8), (2, 7), (2, 9), (2, 9), (2, 10), (2, 9), (2, 10), (2, 7), (2, 9), (2, 10), (2, 8), (2, 9), (2, 10), (2, 8), (2, 9), (2, 8), (2, 10), (2, 8), (2, 9), (2, 9), (2, 8), (2, 9), (2, 10), (2, 6), (2, 9), (2, 7), (2, 10), (2, 9), (2, 10), (2, 6), (2, 10), (2, 9), (2, 9), (2, 9), (2, 8), (2, 10), (2, 9), (2, 8), (2, 7), (2, 8), (2, 8), (2, 8), (2, 7), (2, 8), (2, 8), (2, 9), (2, 8), (2, 9), (2, 7), (2, 9), (2, 9), (2, 8), (2, 9), (2, 9), (2, 6), (2, 7), (2, 7), (2, 9), (2, 8), (2, 8), (2, 7), (2, 7), (2, 8), (2, 9), (2, 7), (2, 9), (2, 9), (2, 8), (2, 8), (2, 5), (2, 9), (2, 9), (2, 7), (2, 7), (2, 7), (2, 9), (2, 9), (2, 9), (2, 7), (2, 7), (2, 9), (2, 8), (2, 6), (2, 9), (2, 8), (2, 9), (2, 8), (2, 9), (2, 6), (2, 8), (2, 9), (2, 7), (2, 8), (2, 9), (2, 7), (2, 9), (2, 7), (2, 9), (2, 7), (2, 8), (2, 8), (2, 7), (2, 8), (2, 9), (2, 5), (2, 8), (2, 11), (2, 11), (2, 7), (2, 12), (2, 11), (2, 10), (2, 10), (2, 10), (2, 12), (2, 11), (2, 10), (2, 9), (2, 9), (2, 10), (2, 9), (2, 8), (2, 10), (2, 10), (2, 11), (2, 10), (2, 11), (2, 8), (2, 10), (2, 11), (2, 9), (2, 10), (2, 11), (2, 8), (2, 9), (2, 8), (2, 11), (2, 9), (2, 10), (2, 9), (2, 9), (2, 10), (2, 11), (2, 7), (2, 10), (2, 10), (2, 7), (2, 11), (2, 10), (2, 9), (2, 10), (2, 9), (2, 11), (2, 10), (2, 9), (2, 8), (2, 9), (2, 9), (2, 8), (2, 8), (2, 9), (2, 9), (2, 10), (2, 9), (2, 10), (2, 8), (2, 9), (2, 10), (2, 8), (2, 9), (2, 10), (2, 8), (2, 8), (2, 7), (2, 10), (2, 8), (2, 10), (2, 8), (2, 9), (2, 9), (2, 10), (2, 6), (2, 9), (2, 6), (2, 11), (2, 10), (2, 10), (2, 9), (2, 9), (2, 11), (2, 10), (2, 9), (2, 8), (2, 8), (2, 9), (2, 9), (2, 7), (2, 9), (2, 9), (2, 10), (2, 9), (2, 10), (2, 8), (2, 10), (2, 10), (2, 8), (2, 10), (2, 10), (2, 7), (2, 8), (2, 7), (2, 10), (2, 8), (2, 9), (2, 8), (2, 8), (2, 9), (2, 10), (2, 7), (2, 9), (2, 7), (2, 6), (2, 5), (2, 7), (2, 6), (2, 7), (2, 7), (2, 6), (2, 7), (2, 7), (2, 6), (2, 5), (2, 7), (2, 6), (2, 6), (2, 7), (2, 7), (2, 7), (2, 6), (2, 6), (2, 7), (2, 7), (2, 6), (2, 7), (2, 5), (2, 5), (2, 5), (2, 7), (2, 7), (2, 7), (2, 6), (2, 7), (2, 7), (2, 7), (2, 4), (2, 7), (2, 11), (2, 10), (2, 10), (2, 10), (2, 12), (2, 11), (2, 10), (2, 9), (2, 9), (2, 10), (2, 9), (2, 8), (2, 10), (2, 10), (2, 11), (2, 10), (2, 11), (2, 8), (2, 10), (2, 11), (2, 9), (2, 10), (2, 11), (2, 8), (2, 9), (2, 8), (2, 11), (2, 9), (2, 10), (2, 9), (2, 9), (2, 10), (2, 11), (2, 7), (2, 10), (2, 9), (2, 9), (2, 9), (2, 11), (2, 10), (2, 9), (2, 8), (2, 8), (2, 9), (2, 9), (2, 7), (2, 10), (2, 9), (2, 10), (2, 9), (2, 10), (2, 7), (2, 9), (2, 10), (2, 8), (2, 9), (2, 10), (2, 7), (2, 9), (2, 7), (2, 10), (2, 8), (2, 9), (2, 8), (2, 8), (2, 9), (2, 10), (2, 6), (2, 9), (2, 8), (2, 9), (2, 10), (2, 9), (2, 8), (2, 7), (2, 7), (2, 8), (2, 8), (2, 6), (2, 8), (2, 9), (2, 9), (2, 8), (2, 9), (2, 7), (2, 9), (2, 9), (2, 7), (2, 9), (2, 9), (2, 7), (2, 7), (2, 7), (2, 9), (2, 7), (2, 8), (2, 7), (2, 7), (2, 8), (2, 9), (2, 7), (2, 8), (2, 8), (2, 10), (2, 9), (2, 8), (2, 7), (2, 9), (2, 8), (2, 7), (2, 8), (2, 8), (2, 8), (2, 9), (2, 8), (2, 9), (2, 7), (2, 8), (2, 9), (2, 8), (2, 8), (2, 9), (2, 7), (2, 7), (2, 7), (2, 9), (2, 8), (2, 9), (2, 7), (2, 8), (2, 8), (2, 9), (2, 6), (2, 9), (2, 10), (2, 9), (2, 8), (2, 8), (2, 7), (2, 8), (2, 7), (2, 7), (2, 8), (2, 9), (2, 9), (2, 8), (2, 9), (2, 7), (2, 8), (2, 9), (2, 8), (2, 8), (2, 9), (2, 7), (2, 7), (2, 7), (2, 9), (2, 7), (2, 8), (2, 7), (2, 7), (2, 8), (2, 9), (2, 6), (2, 8), (2, 11), (2, 10), (2, 9), (2, 9), (2, 10), (2, 9), (2, 8), (2, 10), (2, 10), (2, 11), (2, 10), (2, 11), (2, 8), (2, 10), (2, 11), (2, 9), (2, 10), (2, 11), (2, 8), (2, 9), (2, 8), (2, 11), (2, 9), (2, 10), (2, 9), (2, 9), (2, 10), (2, 11), (2, 7), (2, 10), (2, 11), (2, 10), (2, 10), (2, 11), (2, 10), (2, 9), (2, 11), (2, 11), (2, 12), (2, 10), (2, 11), (2, 9), (2, 11), (2, 12), (2, 10), (2, 11), (2, 12), (2, 9), (2, 10), (2, 9), (2, 12), (2, 10), (2, 11), (2, 9), (2, 10), (2, 11), (2, 12), (2, 8), (2, 11), (2, 9), (2, 9), (2, 11), (2, 9), (2, 8), (2, 10), (2, 10), (2, 11), (2, 9), (2, 10), (2, 8), (2, 10), (2, 11), (2, 9), (2, 10), (2, 11), (2, 9), (2, 10), (2, 9), (2, 11), (2, 9), (2, 10), (2, 9), (2, 9), (2, 10), (2, 11), (2, 7), (2, 10), (2, 8), (2, 9), (2, 8), (2, 8), (2, 9), (2, 9), (2, 10), (2, 9), (2, 9), (2, 8), (2, 9), (2, 10), (2, 9), (2, 9), (2, 10), (2, 7), (2, 8), (2, 7), (2, 10), (2, 9), (2, 9), (2, 8), (2, 9), (2, 10), (2, 10), (2, 6), (2, 9), (2, 9), (2, 8), (2, 9), (2, 9), (2, 9), (2, 10), (2, 8), (2, 9), (2, 8), (2, 9), (2, 10), (2, 9), (2, 9), (2, 10), (2, 8), (2, 8), (2, 8), (2, 10), (2, 9), (2, 10), (2, 7), (2, 9), (2, 9), (2, 10), (2, 7), (2, 10), (2, 9), (2, 8), (2, 10), (2, 10), (2, 11), (2, 9), (2, 10), (2, 8), (2, 10), (2, 11), (2, 9), (2, 10), (2, 11), (2, 9), (2, 10), (2, 9), (2, 11), (2, 9), (2, 10), (2, 9), (2, 9), (2, 10), (2, 11), (2, 7), (2, 10), (2, 7), (2, 10), (2, 9), (2, 10), (2, 8), (2, 9), (2, 8), (2, 10), (2, 10), (2, 8), (2, 10), (2, 10), (2, 7), (2, 9), (2, 7), (2, 10), (2, 8), (2, 9), (2, 7), (2, 8), (2, 9), (2, 10), (2, 7), (2, 9), (2, 8), (2, 8), (2, 9), (2, 7), (2, 8), (2, 8), (2, 8), (2, 9), (2, 9), (2, 8), (2, 9), (2, 7), (2, 7), (2, 7), (2, 9), (2, 8), (2, 9), (2, 6), (2, 8), (2, 8), (2, 9), (2, 6), (2, 9), (2, 10), (2, 11), (2, 9), (2, 10), (2, 8), (2, 10), (2, 11), (2, 9), (2, 10), (2, 11), (2, 8), (2, 10), (2, 8), (2, 11), (2, 9), (2, 10), (2, 8), (2, 9), (2, 10), (2, 11), (2, 7), (2, 10), (2, 11), (2, 9), (2, 10), (2, 8), (2, 10), (2, 11), (2, 9), (2, 10), (2, 11), (2, 9), (2, 9), (2, 9), (2, 11), (2, 9), (2, 10), (2, 8), (2, 9), (2, 10), (2, 11), (2, 8), (2, 10), (2, 10), (2, 11), (2, 9), (2, 11), (2, 12), (2, 10), (2, 11), (2, 12), (2, 9), (2, 10), (2, 9), (2, 12), (2, 10), (2, 11), (2, 9), (2, 10), (2, 11), (2, 12), (2, 8), (2, 11), (2, 10), (2, 7), (2, 9), (2, 10), (2, 8), (2, 9), (2, 10), (2, 7), (2, 8), (2, 7), (2, 10), (2, 9), (2, 9), (2, 9), (2, 9), (2, 10), (2, 10), (2, 6), (2, 9), (2, 8), (2, 10), (2, 11), (2, 9), (2, 10), (2, 11), (2, 8), (2, 9), (2, 8), (2, 11), (2, 9), (2, 10), (2, 9), (2, 9), (2, 10), (2, 11), (2, 7), (2, 10), (2, 9), (2, 9), (2, 8), (2, 9), (2, 9), (2, 7), (2, 7), (2, 6), (2, 9), (2, 7), (2, 9), (2, 6), (2, 8), (2, 8), (2, 9), (2, 6), (2, 8), (2, 11), (2, 9), (2, 11), (2, 11), (2, 8), (2, 9), (2, 8), (2, 11), (2, 9), (2, 10), (2, 8), (2, 9), (2, 10), (2, 11), (2, 8), (2, 10), (2, 10), (2, 11), (2, 12), (2, 9), (2, 10), (2, 9), (2, 12), (2, 10), (2, 11), (2, 9), (2, 10), (2, 11), (2, 12), (2, 8), (2, 11), (2, 9), (2, 10), (2, 7), (2, 8), (2, 8), (2, 10), (2, 9), (2, 9), (2, 7), (2, 8), (2, 9), (2, 10), (2, 7), (2, 10), (2, 11), (2, 8), (2, 9), (2, 8), (2, 11), (2, 9), (2, 10), (2, 8), (2, 9), (2, 10), (2, 11), (2, 8), (2, 10), (2, 9), (2, 10), (2, 9), (2, 12), (2, 10), (2, 11), (2, 9), (2, 10), (2, 11), (2, 12), (2, 8), (2, 11), (2, 8), (2, 8), (2, 9), (2, 7), (2, 9), (2, 7), (2, 8), (2, 8), (2, 9), (2, 6), (2, 8), (2, 8), (2, 10), (2, 8), (2, 9), (2, 8), (2, 8), (2, 9), (2, 10), (2, 6), (2, 9), (2, 9), (2, 8), (2, 8), (2, 7), (2, 7), (2, 8), (2, 9), (2, 7), (2, 9), (2, 10), (2, 11), (2, 9), (2, 10), (2, 11), (2, 12), (2, 8), (2, 11), (2, 9), (2, 8), (2, 9), (2, 10), (2, 10), (2, 7), (2, 10), (2, 8), (2, 10), (2, 10), (2, 11), (2, 7), (2, 10), (2, 8), (2, 9), (2, 9), (2, 5), (2, 8), (2, 10), (2, 10), (2, 6), (2, 9), (2, 11), (2, 7), (2, 10), (2, 8), (2, 11), (2, 8)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_users = len(df)\n",
        "results = []\n",
        "\n",
        "for i in range(num_users):\n",
        "    for j in range(i + 1, num_users):  # Compare each unique pair of users\n",
        "        # Find items co-rated by both users\n",
        "        co_rated_items = df.iloc[i].notna() & df.iloc[j].notna()  # Using iloc to correctly index rows\n",
        "        no_coRated_items = co_rated_items.sum()  # Count of co-rated items\n",
        "\n",
        "        if no_coRated_items > 0:\n",
        "            results.append((2, no_coRated_items))  # Append as a tuple: (2 users, co-rated items)\n",
        "\n",
        "# Step 2: Create 2D array for co-rated counts\n",
        "co_rated_data = np.array(results, dtype=[('No_common_users', int), ('No_coRated_items', int)])\n",
        "\n",
        "# Step 3: Sort the array based on 'No_common_users' in descending order\n",
        "co_rated_array = np.sort(co_rated_data, order='No_common_users')[::-1]\n",
        "\n",
        "# Step 4: Print the final sorted array\n",
        "print(\"Sorted 2D Array of Co-Rated Counts:\")\n",
        "print(co_rated_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU1J7P97pAXI",
        "outputId": "4868e437-eaca-4d0d-d324-92637948a999"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted 2D Array of Co-Rated Counts:\n",
            "[(2, 11) (2, 11) (2, 11) (2, 11) (2, 11) (2, 11) (2, 11) (2, 11) (2, 11)\n",
            " (2, 11) (2, 11) (2, 11) (2, 11) (2, 11) (2, 11) (2, 11) (2, 11) (2, 11)\n",
            " (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10)\n",
            " (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10)\n",
            " (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10)\n",
            " (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10)\n",
            " (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10)\n",
            " (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10)\n",
            " (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10)\n",
            " (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10)\n",
            " (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10)\n",
            " (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2, 10)\n",
            " (2, 10) (2, 10) (2, 10) (2, 10) (2, 10) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9)\n",
            " (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  9) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8)\n",
            " (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  8) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7)\n",
            " (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  7) (2,  6) (2,  6)\n",
            " (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6)\n",
            " (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6)\n",
            " (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6)\n",
            " (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6)\n",
            " (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6)\n",
            " (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6)\n",
            " (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6)\n",
            " (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6)\n",
            " (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6)\n",
            " (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6)\n",
            " (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6)\n",
            " (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6)\n",
            " (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  6) (2,  5) (2,  5)\n",
            " (2,  5) (2,  5) (2,  5) (2,  5) (2,  5) (2,  5) (2,  5) (2,  5) (2,  5)\n",
            " (2,  5) (2,  5) (2,  5) (2,  5) (2,  5) (2,  5) (2,  5) (2,  5) (2,  5)\n",
            " (2,  5) (2,  5) (2,  5) (2,  5) (2,  5) (2,  5) (2,  5) (2,  5) (2,  5)\n",
            " (2,  5) (2,  5) (2,  5) (2,  4) (2,  4) (2,  4) (2,  4) (2,  4) (2,  4)\n",
            " (2,  4) (2,  4) (2,  3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "item_ratings_count = df.count(axis=0)\n",
        "plt.figure(figsize=(10, 6))\n",
        "item_ratings_count.plot(kind='bar', color='blue', edgecolor='black')\n",
        "plt.xlabel('Items (Books)')\n",
        "plt.ylabel('Number of Ratings')\n",
        "plt.title('Distribution of Ratings for Each Item')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "poXshg2dY63O",
        "outputId": "b2e04096-940b-4abc-d297-c8133ac2f7dc"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_items = df.shape[1]\n",
        "threshold = int(0.5 * total_items)\n",
        "print(f\"Threshold for co-rated items: {threshold} items\")\n",
        "\n",
        "active_users = [3, 6, 41]\n",
        "\n",
        "\n",
        "max_users_per_active_user = []\n",
        "\n",
        "if len(df) > 41:\n",
        "    for active_user in active_users:\n",
        "        count_users_meeting_threshold = 0\n",
        "\n",
        "        for other_user in range(df.shape[0]):\n",
        "            if active_user != other_user:\n",
        "\n",
        "                co_rated_items = df.loc[active_user].notna() & df.loc[other_user].notna()\n",
        "                no_coRated_items = co_rated_items.sum()\n",
        "\n",
        "                if no_coRated_items >= threshold:\n",
        "                    count_users_meeting_threshold += 1\n",
        "\n",
        "        max_users_per_active_user.append(count_users_meeting_threshold)\n",
        "\n",
        "final_max_users = max(max_users_per_active_user)\n",
        "\n",
        "\n",
        "print(f\"Maximum number of users meeting the threshold for any active user: {final_max_users}\")\n",
        "print(f\"Users meeting threshold per active user: {max_users_per_active_user}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gly0ImaZ7o4Y",
        "outputId": "894e2d0a-cdff-4ba2-bb22-299dab0b9fa0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold for co-rated items: 6 items\n",
            "Maximum number of users meeting the threshold for any active user: 42\n",
            "Users meeting threshold per active user: [42, 35, 39]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 1.1"
      ],
      "metadata": {
        "id": "imZciyDsB7hF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "filled_items = items.fillna(0)\n",
        "cosine_sim = cosine_similarity(filled_items)\n",
        "cosine_sim_df = pd.DataFrame(cosine_sim, index=items.index, columns=items.index)\n",
        "\n",
        "def compute_discounted_similarity(sim_matrix, threshold):\n",
        "    # Discount similarity above the threshold\n",
        "    return np.where(sim_matrix > threshold, sim_matrix / (1 + threshold), 0)\n",
        "\n",
        "\n",
        "discount_factor = 8\n",
        "discounted_cosine_sim_df = pd.DataFrame(compute_discounted_similarity(cosine_sim_df, discount_factor), index=cosine_sim_df.index, columns=cosine_sim_df.columns)\n",
        "\n",
        "# Function to get the top k similar users based on similarity matrix\n",
        "def get_top_k_users(similarity_matrix, k_percent):\n",
        "    k = int(similarity_matrix.shape[0] * k_percent)\n",
        "    top_users = {}\n",
        "    for user in similarity_matrix.index:\n",
        "        similar_users = similarity_matrix.loc[user].sort_values(ascending=False).iloc[1:k+1]  # Exclude self (0 similarity)\n",
        "        top_users[user] = similar_users.index.tolist()\n",
        "    return top_users\n",
        "\n",
        "top_20_percent_users = get_top_k_users(cosine_sim_df, 0.2)\n",
        "\n",
        "top_20_percent_users_ds = get_top_k_users(discounted_cosine_sim_df, 0.2)\n",
        "\n",
        "def predict_ratings(active_user, top_users, df):\n",
        "    active_user_ratings = df.loc[active_user]\n",
        "    predictions = {}\n",
        "    for item in df.columns:\n",
        "        if pd.isna(active_user_ratings[item]):  # Predict only missing ratings\n",
        "            similar_users = top_users[active_user]\n",
        "            ratings = df.loc[similar_users, item].dropna()\n",
        "            if len(ratings) > 0:\n",
        "                predictions[item] = ratings.mean()\n",
        "    return predictions\n",
        "\n",
        "U1_index = U1.name\n",
        "U2_index = U2.index[0]\n",
        "U3_index = U3.index[0]\n",
        "\n",
        "users_to_predict = [U1_index, U2_index,U3_index]\n",
        "\n",
        "for user in users_to_predict:\n",
        "    print(f\"Top 20% closest users for {user} (Original Cosine Similarity): {top_20_percent_users[user]}\")\n",
        "    predictions = predict_ratings(user, top_20_percent_users, df)\n",
        "    print(f\"Predictions for {user} (Original Cosine Similarity): {predictions}\")\n",
        "\n",
        "    print(f\"Top 20% closest users for {user} (Discounted Cosine Similarity): {top_20_percent_users_ds[user]}\")\n",
        "    predictions_ds = predict_ratings(user, top_20_percent_users_ds, df)\n",
        "    print(f\"Predictions for {user} (Discounted Cosine Similarity): {predictions_ds}\")\n",
        "\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhJ5aqXQzZno",
        "outputId": "9886e6be-5337-4cb3-a3ab-c8e04a31c292"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20% closest users for 4 (Original Cosine Similarity): [25, 8, 11, 24, 26, 16, 36, 23]\n",
            "Predictions for 4 (Original Cosine Similarity): {'1984': 2.8, 'picture of dorian': 1.75}\n",
            "Top 20% closest users for 4 (Discounted Cosine Similarity): [32, 24, 25, 26, 27, 28, 29, 30]\n",
            "Predictions for 4 (Discounted Cosine Similarity): {'1984': 3.2857142857142856, 'picture of dorian': 2.4285714285714284}\n",
            "--------------------------------------------------\n",
            "Top 20% closest users for 2 (Original Cosine Similarity): [14, 32, 12, 34, 20, 18, 24, 23]\n",
            "Predictions for 2 (Original Cosine Similarity): {'jane eyre': 1.8333333333333333, 'picture of dorian ': 5.0, 'tale of cities': 0.6, 'picture of dorian': 3.2}\n",
            "Top 20% closest users for 2 (Discounted Cosine Similarity): [32, 24, 25, 26, 27, 28, 29, 30]\n",
            "Predictions for 2 (Discounted Cosine Similarity): {'jane eyre': 2.5714285714285716, 'tale of cities': 1.8571428571428572, 'picture of dorian': 2.4285714285714284}\n",
            "--------------------------------------------------\n",
            "Top 20% closest users for 5 (Original Cosine Similarity): [9, 12, 3, 7, 8, 0, 4, 11]\n",
            "Predictions for 5 (Original Cosine Similarity): {'The Great Gatsby': 2.847142857142857}\n",
            "Top 20% closest users for 5 (Discounted Cosine Similarity): [32, 24, 25, 26, 27, 28, 29, 30]\n",
            "Predictions for 5 (Discounted Cosine Similarity): {'The Great Gatsby': 1.6, 'picture of dorian': 2.4285714285714284}\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 1.2\n"
      ],
      "metadata": {
        "id": "36B-KrARLoZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "mean_centered_df = items.sub(items.mean(axis=1), axis=0)\n",
        "filled_centered_df = mean_centered_df.fillna(0)\n",
        "\n",
        "cosine_sim_centered = cosine_similarity(filled_centered_df)\n",
        "cosine_sim_centered_df = pd.DataFrame(cosine_sim_centered, index=items.index, columns=items.index)\n",
        "\n",
        "\n",
        "def get_top_k_users(similarity_matrix, k_percent):\n",
        "    k = int(similarity_matrix.shape[0] * k_percent)\n",
        "    top_users = {}\n",
        "    for user in similarity_matrix.index:\n",
        "        similar_users = similarity_matrix.loc[user].sort_values(ascending=False).iloc[1:k+1]  # Exclude self\n",
        "        top_users[user] = similar_users.index.tolist()\n",
        "    return top_users\n",
        "\n",
        "top_20_percent_users_centered = get_top_k_users(cosine_sim_centered_df, 0.2)\n",
        "\n",
        "\n",
        "def predict_ratings(active_user, top_users, df):\n",
        "    active_user_ratings = df.loc[active_user]\n",
        "    predictions = {}\n",
        "    for item in df.columns:\n",
        "        if pd.isna(active_user_ratings[item]):\n",
        "            similar_users = top_users[active_user]\n",
        "            ratings = df.loc[similar_users, item].dropna()\n",
        "            if len(ratings) > 0:\n",
        "                predictions[item] = ratings.mean()\n",
        "    return predictions\n",
        "\n",
        "\n",
        "users_to_predict = items.index[:3]\n",
        "\n",
        "print(\"Predictions using mean-centered cosine similarity:\")\n",
        "print(\"-\" * 50)\n",
        "for user in users_to_predict:\n",
        "    predictions_centered = predict_ratings(user, top_20_percent_users_centered, items)\n",
        "    print(f\"Top 20% closest users for {user}: {top_20_percent_users_centered[user]}\")\n",
        "    print(f\"Predictions with mean-centering for {user}: {predictions_centered}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "def compute_discounted_similarity(sim_matrix, threshold, discount_factor, apply_discount=True):\n",
        "\n",
        "    discounted_sim = np.copy(sim_matrix)\n",
        "    if apply_discount:\n",
        "        discounted_sim[discounted_sim > threshold] /= (1 + discount_factor)  # Apply discount to high similarity values\n",
        "    return discounted_sim\n",
        "\n",
        "threshold = 0.3\n",
        "discount_factor = 0.5\n",
        "apply_discount = True\n",
        "\n",
        "discounted_sim = compute_discounted_similarity(cosine_sim_centered_df, threshold, discount_factor, apply_discount)\n",
        "discounted_sim_df = pd.DataFrame(discounted_sim, index=cosine_sim_centered_df.index, columns=cosine_sim_centered_df.index)\n",
        "\n",
        "top_20_percent_users_ds = get_top_k_users(discounted_sim_df, 0.2)\n",
        "\n",
        "print(\"Predictions using discounted similarity:\")\n",
        "print(\"-\" * 50)\n",
        "for user in users_to_predict:\n",
        "    predictions_ds = predict_ratings(user, top_20_percent_users_ds, items)\n",
        "    print(f\"Top 20% closest users for {user} (Discounted Similarity): {top_20_percent_users_ds[user]}\")\n",
        "    print(f\"Predictions for {user} using Discounted Similarity: {predictions_ds}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQrQiqwveidh",
        "outputId": "633cedbe-3cec-41ee-e6da-042557213c2c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions using mean-centered cosine similarity:\n",
            "--------------------------------------------------\n",
            "Top 20% closest users for 0: [7, 21, 39, 37, 41, 25, 30, 9]\n",
            "Predictions with mean-centering for 0: {'jane eyre': 3.5714285714285716, 'picture of dorian': 1.0}\n",
            "--------------------------------------------------\n",
            "Top 20% closest users for 1: [27, 9, 23, 20, 38, 15, 29, 6]\n",
            "Predictions with mean-centering for 1: {'macbeth': 2.2857142857142856, 'The Great Gatsby': 2.3333333333333335, 'picture of dorian': 2.6}\n",
            "--------------------------------------------------\n",
            "Top 20% closest users for 2: [15, 41, 30, 14, 32, 12, 10, 18]\n",
            "Predictions with mean-centering for 2: {'jane eyre': 2.1666666666666665, 'picture of dorian ': 2.5, 'tale of cities': 1.6666666666666667, 'picture of dorian': 2.6666666666666665}\n",
            "--------------------------------------------------\n",
            "Predictions using discounted similarity:\n",
            "--------------------------------------------------\n",
            "Top 20% closest users for 0 (Discounted Similarity): [7, 21, 30, 39, 9, 37, 32, 41]\n",
            "Predictions for 0 using Discounted Similarity: {'jane eyre': 3.5, 'picture of dorian': 1.6}\n",
            "--------------------------------------------------\n",
            "Top 20% closest users for 1 (Discounted Similarity): [27, 9, 23, 20, 38, 15, 29, 26]\n",
            "Predictions for 1 using Discounted Similarity: {'macbeth': 2.5, 'The Great Gatsby': 1.8, 'picture of dorian': 2.5}\n",
            "--------------------------------------------------\n",
            "Top 20% closest users for 2 (Discounted Similarity): [15, 41, 30, 14, 32, 12, 24, 10]\n",
            "Predictions for 2 using Discounted Similarity: {'jane eyre': 2.8333333333333335, 'picture of dorian ': 2.5, 'tale of cities': 1.5714285714285714, 'picture of dorian': 2.2}\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 1.3"
      ],
      "metadata": {
        "id": "w6ZEPi40M4Eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/expanded_dataset_with_names.xlsx'\n",
        "df = pd.read_excel(file_path).set_index('users')\n",
        "\n",
        "\n",
        "data_matrix = df.to_numpy()\n",
        "\n",
        "\n",
        "def calculate_pcc(matrix):\n",
        "    n_users = matrix.shape[0]\n",
        "    pcc_matrix = np.zeros((n_users, n_users))\n",
        "\n",
        "    for i in range(n_users):\n",
        "        for j in range(i + 1, n_users):\n",
        "\n",
        "            common = ~np.isnan(matrix[i]) & ~np.isnan(matrix[j])\n",
        "\n",
        "            if np.sum(common) > 1:\n",
        "                pcc, _ = pearsonr(matrix[i, common], matrix[j, common])\n",
        "                pcc_matrix[i, j] = pcc\n",
        "                pcc_matrix[j, i] = pcc\n",
        "            else:\n",
        "                pcc_matrix[i, j] = 0\n",
        "                pcc_matrix[j, i] = 0\n",
        "\n",
        "    return pcc_matrix\n",
        "\n",
        "\n",
        "pcc_matrix = calculate_pcc(data_matrix)\n",
        "\n",
        "\n",
        "def get_top_users(pcc_matrix, top_percent=0.2):\n",
        "    n_users = pcc_matrix.shape[0]\n",
        "    top_users = {}\n",
        "\n",
        "    for i in range(n_users):\n",
        "\n",
        "        similarities = [(j, pcc_matrix[i, j]) for j in range(n_users) if j != i]\n",
        "        similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
        "        top_k = int(len(similarities) * top_percent)\n",
        "\n",
        "        top_users[i] = [user[0] for user in similarities[:top_k]]\n",
        "\n",
        "    return top_users\n",
        "\n",
        "top_20_users = get_top_users(pcc_matrix)\n",
        "\n",
        "\n",
        "def predict_ratings(matrix, pcc_matrix, top_users):\n",
        "    predictions = np.copy(matrix)\n",
        "    n_items = matrix.shape[1]\n",
        "\n",
        "    for user in range(len(top_users)):\n",
        "        for item in range(n_items):\n",
        "            if np.isnan(matrix[user, item]):\n",
        "                neighbors = [neighbor for neighbor in top_users[user] if not np.isnan(matrix[neighbor, item])]\n",
        "\n",
        "                if neighbors:\n",
        "\n",
        "                    num = sum(pcc_matrix[user, neighbor] * matrix[neighbor, item] for neighbor in neighbors)\n",
        "                    denom = sum(abs(pcc_matrix[user, neighbor]) for neighbor in neighbors)\n",
        "\n",
        "                    if denom > 0:\n",
        "                        predictions[user, item] = num / denom\n",
        "\n",
        "    return predictions\n",
        "\n",
        "predicted_ratings = predict_ratings(data_matrix, pcc_matrix, top_20_users)\n",
        "\n",
        "\n",
        "def compute_discounted_similarity(pcc_matrix, threshold):\n",
        "    return np.where(np.abs(pcc_matrix) > threshold, pcc_matrix / (1 + np.abs(pcc_matrix)), 0)\n",
        "\n",
        "discount_factor = 0.5\n",
        "discounted_similarity = compute_discounted_similarity(pcc_matrix, discount_factor)\n",
        "\n",
        "\n",
        "top_20_users_ds = get_top_users(discounted_similarity)\n",
        "\n",
        "predicted_ratings_ds = predict_ratings(data_matrix, discounted_similarity, top_20_users_ds)\n",
        "\n",
        "for user in [2,5,41]:\n",
        "    print(f\"Top 20% nearest users for User {df.index[user]} (Original PCC):\")\n",
        "    nearest_users = top_20_users[user]\n",
        "    for neighbor in nearest_users:\n",
        "        print(f\"  User {df.index[neighbor]} with PCC: {pcc_matrix[user, neighbor]:.2f}\")\n",
        "\n",
        "    print(f\"\\nPredicted ratings for missing values for User {df.index[user]} (Original PCC):\")\n",
        "    for item_idx, item_name in enumerate(df.columns):\n",
        "        if np.isnan(data_matrix[user, item_idx]):\n",
        "            print(f\"  {item_name}: {predicted_ratings[user, item_idx]:.2f}\")\n",
        "\n",
        "    print(f\"\\nTop 20% nearest users for User {df.index[user]} (Discounted Similarity):\")\n",
        "    nearest_users_ds = top_20_users_ds[user]\n",
        "    for neighbor in nearest_users_ds:\n",
        "        print(f\"  User {df.index[neighbor]} with Discounted Similarity: {discounted_similarity[user, neighbor]:.2f}\")\n",
        "\n",
        "    print(f\"\\nPredicted ratings for missing values for User {df.index[user]} (Discounted Similarity):\")\n",
        "    for item_idx, item_name in enumerate(df.columns):\n",
        "        if np.isnan(data_matrix[user, item_idx]):\n",
        "            print(f\"  {item_name}: {predicted_ratings_ds[user, item_idx]:.2f}\")\n",
        "    print(\"\\n---\\n\")\n"
      ],
      "metadata": {
        "id": "BfhQ2NzFMysB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54af9427-7bb7-430f-fec2-a563e73cd614"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-747dc2a5de18>:23: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  pcc, _ = pearsonr(matrix[i, common], matrix[j, common])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20% nearest users for User Matthew (Original PCC):\n",
            "  User Christine Lawson with PCC: 0.89\n",
            "  User John Clark with PCC: 0.87\n",
            "  User Stephen with PCC: 0.76\n",
            "  User Luis Barber with PCC: 0.67\n",
            "  User Mario the lone bookwolf with PCC: 0.66\n",
            "  User Michael Eaton with PCC: 0.62\n",
            "  User Anne with PCC: 0.52\n",
            "  User Tiffany Duke with PCC: 0.48\n",
            "\n",
            "Predicted ratings for missing values for User Matthew (Original PCC):\n",
            "  jane eyre: 2.27\n",
            "  picture of dorian : 2.32\n",
            "  tale of cities: 2.13\n",
            "  picture of dorian: 2.12\n",
            "\n",
            "Top 20% nearest users for User Matthew (Discounted Similarity):\n",
            "  User Christine Lawson with Discounted Similarity: 0.47\n",
            "  User John Clark with Discounted Similarity: 0.47\n",
            "  User Stephen with Discounted Similarity: 0.43\n",
            "  User Luis Barber with Discounted Similarity: 0.40\n",
            "  User Mario the lone bookwolf with Discounted Similarity: 0.40\n",
            "  User Michael Eaton with Discounted Similarity: 0.38\n",
            "  User Anne with Discounted Similarity: 0.34\n",
            "  User Sean Barrs with Discounted Similarity: 0.00\n",
            "\n",
            "Predicted ratings for missing values for User Matthew (Discounted Similarity):\n",
            "  jane eyre: 2.37\n",
            "  picture of dorian : 2.39\n",
            "  tale of cities: 1.85\n",
            "  picture of dorian: 1.90\n",
            "\n",
            "---\n",
            "\n",
            "Top 20% nearest users for User Nayra.Hassan (Original PCC):\n",
            "  User Tiffany Duke with PCC: 0.62\n",
            "  User Stephanie Holt with PCC: 0.46\n",
            "  User Anne with PCC: 0.46\n",
            "  User هدى يحيى with PCC: 0.37\n",
            "  User Ashley Smith with PCC: 0.34\n",
            "  User Henry Avila with PCC: 0.33\n",
            "  User Ahmad Sharabiani with PCC: 0.22\n",
            "  User Kevin Kaiser with PCC: 0.21\n",
            "\n",
            "Predicted ratings for missing values for User Nayra.Hassan (Original PCC):\n",
            "  The Great Gatsby: 3.81\n",
            "  picture of dorian: 3.29\n",
            "\n",
            "Top 20% nearest users for User Nayra.Hassan (Discounted Similarity):\n",
            "  User Tiffany Duke with Discounted Similarity: 0.38\n",
            "  User Sean Barrs with Discounted Similarity: 0.00\n",
            "  User emma with Discounted Similarity: 0.00\n",
            "  User Matthew with Discounted Similarity: 0.00\n",
            "  User Lisa of Troy with Discounted Similarity: 0.00\n",
            "  User Anne with Discounted Similarity: 0.00\n",
            "  User Ahmad Sharabiani with Discounted Similarity: 0.00\n",
            "  User Henry Avila with Discounted Similarity: 0.00\n",
            "\n",
            "Predicted ratings for missing values for User Nayra.Hassan (Discounted Similarity):\n",
            "  The Great Gatsby: 2.00\n",
            "  picture of dorian: 4.00\n",
            "\n",
            "---\n",
            "\n",
            "Top 20% nearest users for User Christine Lawson (Original PCC):\n",
            "  User Anne with PCC: nan\n",
            "  User Jackie Watts with PCC: 0.90\n",
            "  User Matthew with PCC: 0.89\n",
            "  User Stephen with PCC: 0.68\n",
            "  User John Clark with PCC: 0.67\n",
            "  User Ahmad Sharabiani with PCC: 0.65\n",
            "  User Sean Barrs with PCC: 0.65\n",
            "  User Dawn Jones with PCC: 0.61\n",
            "\n",
            "Predicted ratings for missing values for User Christine Lawson (Original PCC):\n",
            "  picture of dorian : 2.95\n",
            "  sense and sensibility: nan\n",
            "  brave new world: nan\n",
            "  macbeth: 3.06\n",
            "  The Great Gatsby: nan\n",
            "\n",
            "Top 20% nearest users for User Christine Lawson (Discounted Similarity):\n",
            "  User Jackie Watts with Discounted Similarity: 0.47\n",
            "  User Matthew with Discounted Similarity: 0.47\n",
            "  User Stephen with Discounted Similarity: 0.41\n",
            "  User John Clark with Discounted Similarity: 0.40\n",
            "  User Ahmad Sharabiani with Discounted Similarity: 0.40\n",
            "  User Sean Barrs with Discounted Similarity: 0.40\n",
            "  User Dawn Jones with Discounted Similarity: 0.38\n",
            "  User emma with Discounted Similarity: 0.00\n",
            "\n",
            "Predicted ratings for missing values for User Christine Lawson (Discounted Similarity):\n",
            "  picture of dorian : 2.97\n",
            "  sense and sensibility: 3.10\n",
            "  brave new world: 1.73\n",
            "  macbeth: 3.11\n",
            "  The Great Gatsby: 3.51\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 2.1"
      ],
      "metadata": {
        "id": "mjDTPMObWjNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/expanded_dataset_with_names.xlsx'\n",
        "df = pd.read_excel(file_path).set_index('users')\n",
        "\n",
        "data_matrix = df.to_numpy()\n",
        "\n",
        "def calculate_cosine_similarity(matrix):\n",
        "    item_matrix = np.nan_to_num(matrix.T)\n",
        "    cosine_sim = cosine_similarity(item_matrix)\n",
        "    return cosine_sim\n",
        "\n",
        "cosine_sim_matrix = calculate_cosine_similarity(data_matrix)\n",
        "\n",
        "def get_top_items(sim_matrix, top_percent=0.25):\n",
        "    n_items = sim_matrix.shape[0]\n",
        "    top_items = {}\n",
        "\n",
        "    for i in range(n_items):\n",
        "        similarities = [(j, sim_matrix[i, j]) for j in range(n_items) if j != i]\n",
        "        similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
        "        top_k = int(len(similarities) * top_percent)\n",
        "        top_items[i] = [item[0] for item in similarities[:top_k]]\n",
        "\n",
        "    return top_items\n",
        "\n",
        "top_25_items = get_top_items(cosine_sim_matrix, top_percent=0.25)\n",
        "\n",
        "def predict_item_ratings(matrix, sim_matrix, top_items):\n",
        "    predictions = np.copy(matrix)\n",
        "    n_users, n_items = matrix.shape\n",
        "\n",
        "    for item in range(len(top_items)):\n",
        "        for user in range(n_users):\n",
        "            if np.isnan(matrix[user, item]):  # Predict only missing values\n",
        "                neighbors = [neighbor for neighbor in top_items[item] if not np.isnan(matrix[user, neighbor])]\n",
        "\n",
        "                if neighbors:\n",
        "                    # Weighted average of neighbors' ratings\n",
        "                    num = sum(sim_matrix[item, neighbor] * matrix[user, neighbor] for neighbor in neighbors)\n",
        "                    denom = sum(abs(sim_matrix[item, neighbor]) for neighbor in neighbors)\n",
        "\n",
        "                    if denom > 0:\n",
        "                        predictions[user, item] = num / denom\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "predicted_item_ratings = predict_item_ratings(data_matrix, cosine_sim_matrix, top_25_items)\n",
        "\n",
        "def compute_discounted_similarity(sim_matrix, threshold, discount_factor):\n",
        "\n",
        "    discounted_sim = np.copy(sim_matrix)\n",
        "    discounted_sim[discounted_sim > threshold] /= (1 + discount_factor)\n",
        "    return discounted_sim\n",
        "\n",
        "\n",
        "discount_factor = 2\n",
        "threshold = 0.6\n",
        "discounted_similarity_matrix = compute_discounted_similarity(cosine_sim_matrix, threshold, discount_factor)\n",
        "\n",
        "top_20_items_ds = get_top_items(discounted_similarity_matrix, top_percent=0.2)\n",
        "\n",
        "predicted_item_ratings_ds = predict_item_ratings(data_matrix, discounted_similarity_matrix, top_20_items_ds)\n",
        "\n",
        "item_indices = [1, 6]\n",
        "\n",
        "for item in item_indices:\n",
        "    print(f\"Top 25% closest items for Item {df.columns[item]} (Cosine Similarity):\")\n",
        "    nearest_items = top_25_items[item]\n",
        "    for neighbor in nearest_items:\n",
        "        print(f\"  Item {df.columns[neighbor]} with Cosine Similarity: {cosine_sim_matrix[item, neighbor]:.2f}\")\n",
        "\n",
        "    print(f\"\\nPredicted ratings for missing values for Item {df.columns[item]} (Cosine Similarity):\")\n",
        "    for user_idx, user_name in enumerate(df.index):\n",
        "        if np.isnan(data_matrix[user_idx, item]):\n",
        "            print(f\"  User {user_name}: {predicted_item_ratings[user_idx, item]:.2f}\")\n",
        "    print(\"\\n---\\n\")\n",
        "\n",
        "for item in item_indices:\n",
        "    print(f\"Top 20% closest items for Item {df.columns[item]} (Discounted Similarity):\")\n",
        "    nearest_items = top_20_items_ds[item]\n",
        "    for neighbor in nearest_items:\n",
        "        print(f\"  Item {df.columns[neighbor]} with Discounted Similarity: {discounted_similarity_matrix[item, neighbor]:.2f}\")\n",
        "\n",
        "    print(f\"\\nPredicted ratings for missing values for Item {df.columns[item]} (Discounted Similarity):\")\n",
        "    for user_idx, user_name in enumerate(df.index):\n",
        "        if np.isnan(data_matrix[user_idx, item]):\n",
        "            print(f\"  User {user_name}: {predicted_item_ratings_ds[user_idx, item]:.2f}\")\n",
        "    print(\"\\n---\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4fCocoYuLNc",
        "outputId": "825bee97-f63a-4ed9-8896-51408e2354e6"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 25% closest items for Item 1984 (Cosine Similarity):\n",
            "  Item great expectations with Cosine Similarity: 0.72\n",
            "  Item brave new world with Cosine Similarity: 0.71\n",
            "\n",
            "Predicted ratings for missing values for Item 1984 (Cosine Similarity):\n",
            "  User Emily May: 1.99\n",
            "  User Anne: 4.00\n",
            "  User Stephen: 2.51\n",
            "  User Logan Hoffman: 3.49\n",
            "  User Molly Garcia: 2.00\n",
            "  User Dawn Jones: 4.00\n",
            "  User David Terry: 0.50\n",
            "  User Brandy Ward: 0.50\n",
            "  User Amanda Leach: 2.99\n",
            "\n",
            "---\n",
            "\n",
            "Top 25% closest items for Item great expectations (Cosine Similarity):\n",
            "  Item catcher in rye with Cosine Similarity: 0.73\n",
            "  Item 1984 with Cosine Similarity: 0.72\n",
            "\n",
            "Predicted ratings for missing values for Item great expectations (Cosine Similarity):\n",
            "  User Anne: nan\n",
            "  User Luís: 4.51\n",
            "  User John Clark: 4.00\n",
            "  User Molly Garcia: 0.00\n",
            "  User Dawn Jones: 3.00\n",
            "  User Jasmine Williams: 1.48\n",
            "\n",
            "---\n",
            "\n",
            "Top 20% closest items for Item 1984 (Discounted Similarity):\n",
            "  Item tale of cities with Discounted Similarity: 0.59\n",
            "  Item jane eyre with Discounted Similarity: 0.49\n",
            "\n",
            "Predicted ratings for missing values for Item 1984 (Discounted Similarity):\n",
            "  User Emily May: 3.90\n",
            "  User Anne: 3.00\n",
            "  User Stephen: 3.00\n",
            "  User Logan Hoffman: 3.90\n",
            "  User Molly Garcia: 1.00\n",
            "  User Dawn Jones: 2.90\n",
            "  User David Terry: 2.00\n",
            "  User Brandy Ward: 5.00\n",
            "  User Amanda Leach: 2.10\n",
            "\n",
            "---\n",
            "\n",
            "Top 20% closest items for Item great expectations (Discounted Similarity):\n",
            "  Item brave new world with Discounted Similarity: 0.59\n",
            "  Item tale of cities with Discounted Similarity: 0.54\n",
            "\n",
            "Predicted ratings for missing values for Item great expectations (Discounted Similarity):\n",
            "  User Anne: 3.52\n",
            "  User Luís: 5.00\n",
            "  User John Clark: 1.95\n",
            "  User Molly Garcia: 1.52\n",
            "  User Dawn Jones: 3.05\n",
            "  User Jasmine Williams: 3.05\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "file_path = '/content/expanded_dataset_with_names.xlsx'\n",
        "df = pd.read_excel(file_path).set_index('users')\n",
        "\n",
        "data_matrix = df.to_numpy()\n",
        "\n",
        "def calculate_cosine_similarity(matrix):\n",
        "    item_matrix = np.nan_to_num(matrix.T)\n",
        "    cosine_sim = cosine_similarity(item_matrix)\n",
        "    return cosine_sim\n",
        "\n",
        "cosine_sim_matrix = calculate_cosine_similarity(data_matrix)\n",
        "\n",
        "def get_top_items(sim_matrix, top_percent=0.25):\n",
        "    n_items = sim_matrix.shape[0]\n",
        "    top_items = {}\n",
        "\n",
        "    for i in range(n_items):\n",
        "        similarities = [(j, sim_matrix[i, j]) for j in range(n_items) if j != i]\n",
        "        similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
        "        top_k = int(len(similarities) * top_percent)\n",
        "        top_items[i] = [item[0] for item in similarities[:top_k]]\n",
        "\n",
        "    return top_items\n",
        "\n",
        "top_25_items = get_top_items(cosine_sim_matrix, top_percent=0.25)\n",
        "\n",
        "def predict_item_ratings(matrix, sim_matrix, top_items):\n",
        "    predictions = np.copy(matrix)\n",
        "    n_users, n_items = matrix.shape\n",
        "\n",
        "    for item in range(len(top_items)):\n",
        "        for user in range(n_users):\n",
        "            if np.isnan(matrix[user, item]):\n",
        "                neighbors = [neighbor for neighbor in top_items[item] if not np.isnan(matrix[user, neighbor])]\n",
        "\n",
        "                if neighbors:\n",
        "                    num = sum(sim_matrix[item, neighbor] * matrix[user, neighbor] for neighbor in neighbors)\n",
        "                    denom = sum(abs(sim_matrix[item, neighbor]) for neighbor in neighbors)\n",
        "\n",
        "                    if denom > 0:\n",
        "                        predictions[user, item] = num / denom\n",
        "\n",
        "    return predictions\n",
        "\n",
        "predicted_item_ratings = predict_item_ratings(data_matrix, cosine_sim_matrix, top_25_items)\n",
        "\n",
        "def compute_discounted_similarity(sim_matrix, threshold):\n",
        "\n",
        "    discounted_sim = np.where(sim_matrix <= threshold, sim_matrix, 0)\n",
        "    return discounted_sim\n",
        "\n",
        "discount_factor =0.5\n",
        "discounted_similarity_matrix = compute_discounted_similarity(cosine_sim_matrix, discount_factor)\n",
        "\n",
        "top_20_items_ds = get_top_items(discounted_similarity_matrix, top_percent=0.2)\n",
        "\n",
        "predicted_item_ratings_ds = predict_item_ratings(data_matrix, discounted_similarity_matrix, top_20_items_ds)\n",
        "\n",
        "item_indices = [1, 6]\n",
        "for item in item_indices:\n",
        "    print(f\"Top 25% closest items for Item {df.columns[item]} (Original Cosine Similarity):\")\n",
        "    nearest_items = top_25_items[item]\n",
        "    for neighbor in nearest_items:\n",
        "        print(f\"  Item {df.columns[neighbor]} with Cosine Similarity: {cosine_sim_matrix[item, neighbor]:.2f}\")\n",
        "\n",
        "    print(f\"\\nPredicted ratings for missing values for Item {df.columns[item]} (Original Cosine Similarity):\")\n",
        "    for user_idx, user_name in enumerate(df.index):\n",
        "        if np.isnan(data_matrix[user_idx, item]):\n",
        "            print(f\"  User {user_name}: {predicted_item_ratings[user_idx, item]:.2f}\")\n",
        "    print(\"\\n---\\n\")\n",
        "\n",
        "for item in item_indices:\n",
        "    print(f\"Top 20% closest items for Item {df.columns[item]} (Discounted Similarity):\")\n",
        "    nearest_items = top_20_items_ds[item]\n",
        "    for neighbor in nearest_items:\n",
        "        print(f\"  Item {df.columns[neighbor]} with Discounted Similarity: {discounted_similarity_matrix[item, neighbor]:.2f}\")\n",
        "\n",
        "    print(f\"\\nPredicted ratings for missing values for Item {df.columns[item]} (Discounted Similarity):\")\n",
        "    for user_idx, user_name in enumerate(df.index):\n",
        "        if np.isnan(data_matrix[user_idx, item]):\n",
        "            print(f\"  User {user_name}: {predicted_item_ratings_ds[user_idx, item]:.2f}\")\n",
        "    print(\"\\n---\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GObEQW-cHhkn",
        "outputId": "c155113f-b276-4ce3-ba55-b20cf03dc2f6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 25% closest items for Item 1984 (Original Cosine Similarity):\n",
            "  Item great expectations with Cosine Similarity: 0.72\n",
            "  Item brave new world with Cosine Similarity: 0.71\n",
            "\n",
            "Predicted ratings for missing values for Item 1984 (Original Cosine Similarity):\n",
            "  User Emily May: 1.99\n",
            "  User Anne: 4.00\n",
            "  User Stephen: 2.51\n",
            "  User Logan Hoffman: 3.49\n",
            "  User Molly Garcia: 2.00\n",
            "  User Dawn Jones: 4.00\n",
            "  User David Terry: 0.50\n",
            "  User Brandy Ward: 0.50\n",
            "  User Amanda Leach: 2.99\n",
            "\n",
            "---\n",
            "\n",
            "Top 25% closest items for Item great expectations (Original Cosine Similarity):\n",
            "  Item catcher in rye with Cosine Similarity: 0.73\n",
            "  Item 1984 with Cosine Similarity: 0.72\n",
            "\n",
            "Predicted ratings for missing values for Item great expectations (Original Cosine Similarity):\n",
            "  User Anne: nan\n",
            "  User Luís: 4.51\n",
            "  User John Clark: 4.00\n",
            "  User Molly Garcia: 0.00\n",
            "  User Dawn Jones: 3.00\n",
            "  User Jasmine Williams: 1.48\n",
            "\n",
            "---\n",
            "\n",
            "Top 20% closest items for Item 1984 (Discounted Similarity):\n",
            "  Item jane eyre with Discounted Similarity: 0.49\n",
            "  Item picture of dorian with Discounted Similarity: 0.49\n",
            "\n",
            "Predicted ratings for missing values for Item 1984 (Discounted Similarity):\n",
            "  User Emily May: 5.00\n",
            "  User Anne: 3.00\n",
            "  User Stephen: 3.00\n",
            "  User Logan Hoffman: 4.50\n",
            "  User Molly Garcia: 2.50\n",
            "  User Dawn Jones: 2.00\n",
            "  User David Terry: 4.00\n",
            "  User Brandy Ward: 3.00\n",
            "  User Amanda Leach: 2.00\n",
            "\n",
            "---\n",
            "\n",
            "Top 20% closest items for Item great expectations (Discounted Similarity):\n",
            "  Item picture of dorian with Discounted Similarity: 0.44\n",
            "  Item jane eyre with Discounted Similarity: 0.00\n",
            "\n",
            "Predicted ratings for missing values for Item great expectations (Discounted Similarity):\n",
            "  User Anne: nan\n",
            "  User Luís: nan\n",
            "  User John Clark: 2.00\n",
            "  User Molly Garcia: 4.00\n",
            "  User Dawn Jones: 0.00\n",
            "  User Jasmine Williams: 4.00\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case 2.2"
      ],
      "metadata": {
        "id": "fUZ-dYkNicNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/expanded_dataset_with_names.xlsx'\n",
        "df = pd.read_excel(file_path).set_index('users')\n",
        "\n",
        "data_matrix = df.to_numpy()\n",
        "\n",
        "\n",
        "def calculate_mean_centered_cosine_similarity(matrix):\n",
        "    item_matrix = matrix.T\n",
        "    mean_centered_matrix = np.zeros_like(item_matrix)\n",
        "    for i in range(item_matrix.shape[0]):\n",
        "        item = item_matrix[i]\n",
        "        mean = np.nanmean(item)\n",
        "        mean_centered_matrix[i] = np.where(np.isnan(item), 0, item - mean)\n",
        "    cosine_sim = cosine_similarity(mean_centered_matrix)\n",
        "    return cosine_sim\n",
        "\n",
        "mean_centered_cosine_sim_matrix = calculate_mean_centered_cosine_similarity(data_matrix)\n",
        "\n",
        "\n",
        "def get_top_items(sim_matrix, top_percent=0.2):\n",
        "    n_items = sim_matrix.shape[0]\n",
        "    top_items = {}\n",
        "    for i in range(n_items):\n",
        "        similarities = [(j, sim_matrix[i, j]) for j in range(n_items) if j != i]\n",
        "        similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
        "        top_k = int(len(similarities) * top_percent)\n",
        "        top_items[i] = [item[0] for item in similarities[:top_k]]\n",
        "    return top_items\n",
        "\n",
        "top_20_items = get_top_items(mean_centered_cosine_sim_matrix, top_percent=0.2)\n",
        "\n",
        "def predict_item_ratings(matrix, sim_matrix, top_items):\n",
        "    predictions = np.copy(matrix)\n",
        "    n_users, n_items = matrix.shape\n",
        "    for item in range(len(top_items)):\n",
        "        for user in range(n_users):\n",
        "            if np.isnan(matrix[user, item]):  # Predict only missing values\n",
        "                neighbors = [neighbor for neighbor in top_items[item] if not np.isnan(matrix[user, neighbor])]\n",
        "                if neighbors:\n",
        "                    num = sum(sim_matrix[item, neighbor] * matrix[user, neighbor] for neighbor in neighbors)\n",
        "                    denom = sum(abs(sim_matrix[item, neighbor]) for neighbor in neighbors)\n",
        "                    if denom > 0:\n",
        "                        predictions[user, item] = num / denom\n",
        "    return predictions\n",
        "\n",
        "predicted_item_ratings = predict_item_ratings(data_matrix, mean_centered_cosine_sim_matrix, top_20_items)\n",
        "\n",
        "def compute_discounted_similarity(sim_matrix, threshold, discount_factor):\n",
        "    discounted_sim = np.copy(sim_matrix)\n",
        "    discounted_sim[discounted_sim > threshold] /= (1 + discount_factor)\n",
        "    return discounted_sim\n",
        "\n",
        "threshold = 0.1\n",
        "discount_factor = 0.2\n",
        "\n",
        "discounted_similarity_matrix = compute_discounted_similarity(mean_centered_cosine_sim_matrix, threshold, discount_factor)\n",
        "\n",
        "\n",
        "top_20_items_ds = get_top_items(discounted_similarity_matrix, top_percent=0.2)\n",
        "\n",
        "predicted_item_ratings_ds = predict_item_ratings(data_matrix, discounted_similarity_matrix, top_20_items_ds)\n",
        "\n",
        "item_indices = [1, 6]\n",
        "\n",
        "for item in item_indices:\n",
        "    print(f\"Top 20% closest items for Item {df.columns[item]}:\")\n",
        "\n",
        "    nearest_items = top_20_items[item]\n",
        "    for neighbor in nearest_items:\n",
        "        print(f\"  Item {df.columns[neighbor]} with Mean-Centered Cosine Similarity: {mean_centered_cosine_sim_matrix[item, neighbor]:.2f}\")\n",
        "        print(f\"  Item {df.columns[neighbor]} with Discounted Similarity: {discounted_similarity_matrix[item, neighbor]:.2f}\")\n",
        "\n",
        "    print(f\"\\nPredicted ratings for missing values for Item {df.columns[item]}:\")\n",
        "\n",
        "    print(\"  Predictions using Mean-Centered Cosine Similarity:\")\n",
        "    for user_idx, user_name in enumerate(df.index):\n",
        "        if np.isnan(data_matrix[user_idx, item]):\n",
        "            print(f\"    User {user_name}: {predicted_item_ratings[user_idx, item]:.2f}\")\n",
        "\n",
        "    print(\"\\n  Predictions using Discounted Similarity:\")\n",
        "    for user_idx, user_name in enumerate(df.index):\n",
        "        if np.isnan(data_matrix[user_idx, item]):\n",
        "            print(f\"    User {user_name}: {predicted_item_ratings_ds[user_idx, item]:.2f}\")\n",
        "\n",
        "    print(\"\\n---\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hykBOVKwwRwV",
        "outputId": "42a3a8bc-2645-486e-e505-c07a90b6dba9"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20% closest items for Item 1984:\n",
            "  Item great expectations with Mean-Centered Cosine Similarity: 0.15\n",
            "  Item great expectations with Discounted Similarity: 0.13\n",
            "  Item macbeth with Mean-Centered Cosine Similarity: 0.11\n",
            "  Item macbeth with Discounted Similarity: 0.09\n",
            "\n",
            "Predicted ratings for missing values for Item 1984:\n",
            "  Predictions using Mean-Centered Cosine Similarity:\n",
            "    User Emily May: 2.05\n",
            "    User Anne: nan\n",
            "    User Stephen: 5.00\n",
            "    User Logan Hoffman: 2.00\n",
            "    User Molly Garcia: nan\n",
            "    User Dawn Jones: 5.00\n",
            "    User David Terry: 1.82\n",
            "    User Brandy Ward: 2.64\n",
            "    User Amanda Leach: 0.59\n",
            "\n",
            "  Predictions using Discounted Similarity:\n",
            "    User Emily May: 2.05\n",
            "    User Anne: nan\n",
            "    User Stephen: 5.00\n",
            "    User Logan Hoffman: 2.00\n",
            "    User Molly Garcia: nan\n",
            "    User Dawn Jones: 5.00\n",
            "    User David Terry: 1.82\n",
            "    User Brandy Ward: 2.64\n",
            "    User Amanda Leach: 0.59\n",
            "\n",
            "---\n",
            "\n",
            "Top 20% closest items for Item great expectations:\n",
            "  Item catcher in rye with Mean-Centered Cosine Similarity: 0.29\n",
            "  Item catcher in rye with Discounted Similarity: 0.24\n",
            "  Item 1984 with Mean-Centered Cosine Similarity: 0.15\n",
            "  Item 1984 with Discounted Similarity: 0.13\n",
            "\n",
            "Predicted ratings for missing values for Item great expectations:\n",
            "  Predictions using Mean-Centered Cosine Similarity:\n",
            "    User Anne: nan\n",
            "    User Luís: 4.65\n",
            "    User John Clark: 4.00\n",
            "    User Molly Garcia: 0.00\n",
            "    User Dawn Jones: 3.00\n",
            "    User Jasmine Williams: 1.04\n",
            "\n",
            "  Predictions using Discounted Similarity:\n",
            "    User Anne: nan\n",
            "    User Luís: 4.65\n",
            "    User John Clark: 4.00\n",
            "    User Molly Garcia: 0.00\n",
            "    User Dawn Jones: 3.00\n",
            "    User Jasmine Williams: 1.04\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# case 2.3"
      ],
      "metadata": {
        "id": "JLLA7dmYix2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/dataset assignment 2.xlsx'\n",
        "df = pd.read_excel(file_path).set_index('users')\n",
        "data_matrix = df.to_numpy()\n",
        "\n",
        "def calculate_pearson_correlation(matrix):\n",
        "    item_matrix = matrix.T\n",
        "    n_items = item_matrix.shape[0]\n",
        "    pcc_matrix = np.zeros((n_items, n_items))\n",
        "    for i in range(n_items):\n",
        "        for j in range(n_items):\n",
        "            if i != j:\n",
        "                valid_indices = ~np.isnan(item_matrix[i]) & ~np.isnan(item_matrix[j])\n",
        "                if np.any(valid_indices):\n",
        "                    pcc_matrix[i, j], _ = pearsonr(item_matrix[i, valid_indices], item_matrix[j, valid_indices])\n",
        "                else:\n",
        "                    pcc_matrix[i, j] = 0\n",
        "    return pcc_matrix\n",
        "\n",
        "pcc_matrix = calculate_pearson_correlation(data_matrix)\n",
        "\n",
        "def get_top_items(sim_matrix, top_percent=0.2):\n",
        "    n_items = sim_matrix.shape[0]\n",
        "    top_items = {}\n",
        "    for i in range(n_items):\n",
        "        similarities = [(j, sim_matrix[i, j]) for j in range(n_items) if j != i]\n",
        "        similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
        "        top_k = int(len(similarities) * top_percent)\n",
        "        top_items[i] = [item[0] for item in similarities[:top_k]]\n",
        "    return top_items\n",
        "\n",
        "top_20_items_pcc = get_top_items(pcc_matrix, top_percent=0.2)\n",
        "\n",
        "def predict_item_ratings(matrix, sim_matrix, top_items):\n",
        "    predictions = np.copy(matrix)\n",
        "    n_users, n_items = matrix.shape\n",
        "    for item in range(len(top_items)):\n",
        "        for user in range(n_users):\n",
        "            if np.isnan(matrix[user, item]):\n",
        "                neighbors = [neighbor for neighbor in top_items[item] if not np.isnan(matrix[user, neighbor])]\n",
        "                if neighbors:\n",
        "                    num = sum(sim_matrix[item, neighbor] * matrix[user, neighbor] for neighbor in neighbors)\n",
        "                    denom = sum(abs(sim_matrix[item, neighbor]) for neighbor in neighbors)\n",
        "                    if denom > 0:\n",
        "                        predictions[user, item] = num / denom\n",
        "    return predictions\n",
        "\n",
        "predicted_item_ratings_pcc = predict_item_ratings(data_matrix, pcc_matrix, top_20_items_pcc)\n",
        "\n",
        "def compute_discounted_similarity(sim_matrix, threshold, discount_factor):\n",
        "    discounted_sim = np.copy(sim_matrix)\n",
        "    discounted_sim[discounted_sim > threshold] /= (1 + discount_factor)\n",
        "    return discounted_sim\n",
        "\n",
        "threshold = 0.1\n",
        "discount_factor = 0.5\n",
        "discounted_similarity_matrix_pcc = compute_discounted_similarity(pcc_matrix, threshold, discount_factor)\n",
        "\n",
        "top_20_items_ds_pcc = get_top_items(discounted_similarity_matrix_pcc, top_percent=0.2)\n",
        "predicted_item_ratings_ds_pcc = predict_item_ratings(data_matrix, discounted_similarity_matrix_pcc, top_20_items_ds_pcc)\n",
        "\n",
        "item_indices = [0, 1]\n",
        "\n",
        "for item in item_indices:\n",
        "    print(f\"Top 20% closest items for Item {df.columns[item]} (PCC and Discounted Similarity):\")\n",
        "    nearest_items = top_20_items_pcc[item]\n",
        "    for neighbor in nearest_items:\n",
        "        print(f\"  Item {df.columns[neighbor]} with Pearson Correlation: {pcc_matrix[item, neighbor]:.2f}\")\n",
        "        print(f\"  Item {df.columns[neighbor]} with Discounted Similarity: {discounted_similarity_matrix_pcc[item, neighbor]:.2f}\")\n",
        "\n",
        "    print(f\"\\nPredicted ratings for missing values for Item {df.columns[item]}:\")\n",
        "\n",
        "    print(\"  Predictions using Pearson Correlation:\")\n",
        "    for user_idx, user_name in enumerate(df.index):\n",
        "        if np.isnan(data_matrix[user_idx, item]):\n",
        "            print(f\"    User {user_name}: {predicted_item_ratings_pcc[user_idx, item]:.2f}\")\n",
        "\n",
        "    print(\"\\n  Predictions using Discounted Similarity:\")\n",
        "    for user_idx, user_name in enumerate(df.index):\n",
        "        if np.isnan(data_matrix[user_idx, item]):\n",
        "            print(f\"    User {user_name}: {predicted_item_ratings_ds_pcc[user_idx, item]:.2f}\")\n",
        "\n",
        "    print(\"\\n---\\n\")\n"
      ],
      "metadata": {
        "id": "V1ATHiTWe_U1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "3e027e24-50ed-4db7-fed7-5bfa8ee7c038"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/dataset assignment 2.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-b71c18e13479>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/dataset assignment 2.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'users'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdata_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/dataset assignment 2.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i9YKRRpYxV6Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}